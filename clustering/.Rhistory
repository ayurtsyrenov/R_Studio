ayur<-read.table(file=file.choose(), header=TRUE, sep=";")
data<-read.table(file=file.choose(), header= TRUE, sep=",")
summary(data)
View(data)
data<-read.table(file=file.choose(), header= TRUE)
data<-read.table(file=file.choose(), header= TRUE)
summary(data)
View(data)
data<-read.table(file=file.choose(), header= TRUE, sep=";")
View(data)
summary(data)
ts.data<-ts(data$X, start=c(2018,1,1), frequency = 365)
tsdisplay(ts.data)
plot(ts.data)
data<-read.table(file=file.choose(), header= TRUE, sep=";")
summary(data)
library(forecast)
install.packages("forecast")
library(forecast)
library(forecast)
install.packages("tseries")
install.packages("forecast")
library(forecast)
plot(ts.data)
install.packages("forecast")
library(forecast)
tsdisplay(ts.data)
data<-read.table(file=file.choose(), header= TRUE, sep=";")
summary(data)
ts.data<-ts(data$curs, start=c(2000,1,1), frequency = 12)
ts.data<-ts(data$curs, start=c(2000,1,1), frequency = 12)
tsdisplay(ts.data)
library(forecast)
install.packages("forecast")
library(forecast)
install.packages("ggplot2")
library(ggplot)
data<-read.table(file=file.choose(), header= TRUE, sep=";")
summary(data)
reg<-lm(cost~Click, data=data)
install.packages(c("dplyr", "ggplot2", "GGally", "psych"))
library("dplyr")
library("ggplot2")
library("GGally")
library("psych")
d <- cars
glimpse(d)
help(cats)
help(cars)
head(d)
tail(d)
describe(d)
ncol(d)
nrow(d)
strd
str(d)
mean(d$speed)
d2 <- mutate(d, speed=1.67*speed,
dist=0.3*dist, ratio=dist/speed)
glimpse(d2)
# visualization
qplot(data=d2, dist)
# visualization
qplot(data=d2, dist, xlab="Длина тормозного пути", ylab = "Количество машин", main = "Данные 1920х годов")
qplot(data=d2, speed, dist)
# если много переменных, то через +
model <- lm(data=d2, dist~speed)
model
beta_hat <- coef(model)
beta_hat
beta_hat <- coef(model)
beta_hat
eps <- residuals(models)
eps <- residuals(model)
eps
y <- d2$dist
y_hat<-fitted(model)
RSS <-deviance(model)
RSS
TSS <- sum((y-mean(y))^2)
TSS
ESS <- TSS - RSS
ESS
R2 <- ESS/TSS
R2
cor(y,y_hat)
cor(y,y_hat)^2
X <- model.matrix(model)
X
nd <- data.frame(speed=c(40,60))
nd
predict(model, nd)
qplot(data=d2, speed, dist) + stat_smooth(method="lm")
# another data
t <- swiss
summary(t)
glimpse(t)
describe(t)
ggpairs(t)
model2 <- lm(data=t, Fertility~Agriculture
+ Education+Catholic)
model2
#eps
residuals(model2)
#y^
fitted(model2)
#RSS
deviance(model2)
report <- summary(model2)
report
report$r.squared
cor(t$Fertility, fitted(model2))
cor(t$Fertility, fitted(model2))^2
nd2 <- data.frame(Agriculture=0.5, Catholic=0.5, Education=20)
predict(model2,nd2)
library("dplyr") # обработка данных
library("ggplot2") #визуализация
library("GGally") #матрица диаграм рассеивания
library("psych") #описательные статистики
d <- cars
glimpse(d)
help(cars)
head(d)
tail(d)
describe(d)
ncol(d)
nrow(d)
str(d)
mean(d$speed)
# change value
d2 <- mutate(d, speed=1.67*speed,
dist=0.3*dist, ratio=dist/speed)
# change value
d2 <- mutate(d, speed=1.67*speed,
dist=0.3*dist, ratio=dist/speed)
glimpse(d2)
# visualization
qplot(data=d2, dist, xlab="Длина тормозного пути", ylab = "Количество машин", main = "Данные 1920х годов")
qplot(data=d2, speed, dist)
# если много переменных, то через +
model <- lm(data=d2, dist~speed)
model
beta_hat <- coef(model)
beta_hat
eps <- residuals(model)
eps
y <- d2$dist
y_hat<-fitted(model)
RSS <-deviance(model)
RSS
TSS <- sum((y-mean(y))^2)
TSS
ESS <- TSS - RSS
ESS
R2 <- ESS/TSS
R2
cor(y,y_hat)^2
X <- model.matrix(model)
X
rm(list = ls())
basket <- read.table("basketball_1.csv")
basket <- read.table(file = file.choose(), header = TRUE)
basket(head(3))
View(basket)
basket <- read.table(file = file.choose(), header = FALSE)
summary(basket[,1])
hist (basket[,1])
hist(basket[,1], breaks = 8)
hist(basket[,1], breaks = 16)
basket <- read.table(file = file.choose(), header = FALSE)
basket <- read.table(file = file.choose(), header = FALSE)
basket_2 <- read.table(file = file.choose(), header = FALSE)
View(basket_2)
basket_2 <- read.table(file = file.choose(), header = FALSE, sep = ";")
View(basket_2)
bosplot (basket_2[,1]~basket_2[,2])
boxsplot (basket_2[,1]~basket_2[,2])
boxplot (basket_2[,1]~basket_2[,2])
getwd()
setwd("/Users/ayur/Data analytics/R/R_Studio/clustering")
getwd()
basket <- read.table(file = "basketball_1.csv", header = FALSE, sep = ";")
summary(basket[,1])
hist (basket[,1])
hist(basket[,1], breaks = 16)
basket_2 <- read.table(file = "basketball_2.csv", header = FALSE, sep = ";")
# ящиковая диаграмма
boxplot (basket_2[,1]~basket_2[,2])
View(basket)
getwd()
bev <- read.table(file = "beverage.csv", header = TRUE, sep = ";")
bev <- read.table(file = "beverage_r.csv", header = TRUE, sep = ";")
bev <- read.table(file = "beverage_r.csv", header = TRUE, sep = ";")
View(bev)
# создаем матрицу попарных расстояний
dist.bev <- dist(bev[,2:9])
# clustering by WARD method
clust_bev <- hclust(dist.bev, "ward.D")
View(clust_bev)
plot(clust_bev)
clust_bev
plot(clust_bev)
plot(clust_bev, hang = -1)
plot(clust_bev, hang = -1, main = "Clustering",
sub = "Subtitle", xlab = "x", ylab = "y",
)
# add color
rect.hclust(clust_bev, k=3, border = "red")
group <- cutree(clust_bev, k = 3)
group
# вычислим долю пьющих каждый напиток
colMeans(bev[group == 1, 2:9])*100
colMeans(bev[group == 2, 2:9])*100
colMeans(bev[group == 3, 2:9])*100
names(clust_bev)
clust_bev$merge
clust_bev$height
clust_bev$order
clust_bev$labels
clust_bev$method
# строим график "локоть"
plot(1:33, clust_bev$height, main = "Clustering")
# строим график "локоть"
plot(1:33, clust_bev$height, main = "График 'локоть'")
# строим график "локоть"
plot(1:33, clust_bev$height, main = "График 'локоть'",
type = "l")
prot <- read.table(file = "protein.csv", header = TRUE, sep = ";", dec = ",", row.names = TRUE)
prot <- read.table(file = "protein.csv", header = TRUE, sep = ";", dec = ",", row.names = 1)
View(prot)
View(prot)
maxs <- apply(prot, 2:10, max)
mins <- apply(prot, 2:10, min)
prot_2 <- scale(prot, center = mins, scale = maxs - mins)
maxs <- apply(prot, 2, max)
mins <- apply(prot, 2, min)
prot_2 <- scale(prot, center = mins, scale = maxs - mins)
dist_prot_2 <- dist(prot_2[,2:10])
dist_prot_2 <- dist(prot_2[,2:9])
clust_prot_2 <- hclust(dist_prot_2, "ward.D")
clust_prot_2
plot(clust_prot_2, labels = x[,1])
plot(clust_prot_2, labels = clust_prot_2[,1])
plot(clust_prot_2, labels = dist_prot_2[,1])
plot(clust_prot_2, labels = prot_2[,1])
View(prot_2)
plot(clust_prot_2, labels = prot[,1])
prot <- read.table(file = "protein.csv", header = TRUE, sep = ";", dec = ",")
maxs <- apply(prot, 2, max)
mins <- apply(prot, 2, min)
prot_2 <- scale(prot, center = mins, scale = maxs - mins)
dist_prot_2 <- dist(prot_2[,2:10])
dist_prot_2 <- dist(prot_2[,2:9])
clust_prot_2 <- hclust(dist_prot_2, "ward.D")
clust_prot_2
plot(clust_prot_2, labels = prot[,1])
plot(clust_prot_2, labels = prot[,1], hang = -1)
View(prot_2)
maxs <- apply(prot, 2, max)
mins <- apply(prot, 2, min)
prot_2 <- scale(prot, center = mins, scale = maxs - mins)
View(prot)
View(prot_2)
rect.hclust(clust_prot_2, k=4, border = "green")
group_2 <- cutree(clust_prot_2, k=4)
group_2
colMeans(prot_2[group == 1, 2:9])*100
colMeans(prot_2[group == 2, 2:9])*100
colMeans(prot_2[group == 3, 2:9])*100
colMeans(prot_2[group == 4, 2:9])*100
colMeans(prot_2[group == 1, 2:10])*100
colMeans(prot_2[group == 1, 2:8])*100
dist_prot_2 <- dist(prot_2[,2:10])
dist_prot_2 <- dist(prot[,2:10])
dist_prot_2 <- dist(prot_2[,2:10])
maxs <- apply(prot, 1, max)
mins <- apply(prot, 1, min)
prot_2 <- scale(prot, center = mins, scale = maxs - mins)
maxs <- apply(prot, 2, max)
mins <- apply(prot, 2, min)
prot_2 <- scale(prot, center = mins, scale = maxs - mins)
maxs <- apply(prot[,2:10], 2, max)
mins <- apply(prot[,2:10], 2, min)
prot_2 <- scale(prot, center = mins, scale = maxs - mins)
prot_2 <- scale(prot, center = mins, scale = maxs - mins)
prot_2 <- scale(prot, center = mins+1, scale = maxs - mins)
prot_2 <- scale(prot, center = 10, scale = maxs - mins)
prot_2 <- scale(prot, center = TRUE, scale = maxs - mins)
prot <- read.table(file = "protein.csv", header = TRUE, sep = ";", dec = ",")
View(prot)
maxs <- apply(prot[,2:10], 2, max)
mins <- apply(prot[,2:10], 2, min)
prot_2 <- scale(prot, center = mins, scale = maxs - mins)
prot_2 <- scale(prot[,2:10], center=TRUE, scale=TRUE)
View(prot_2)
dist_prot_2 <- dist(prot_2[,2:10])
dist_prot_2 <- dist(prot_2[,2:9])
clust_prot_2 <- hclust(dist_prot_2, "ward.D")
clust_prot_2
plot(clust_prot_2, labels = prot[,1], hang = -1)
rect.hclust(clust_prot_2, k=4, border = "green")
group_2 <- cutree(clust_prot_2, k=4)
group_2
colMeans(prot_2[group == 1, 2:10])*100
colMeans(prot_2[group_2 == 1, 2:10])*100
colMeans(prot_2[group_2 == 1, 2:9])*100
colMeans(prot_2[group_2 == 1, 2:9])*100
colMeans(prot_2[group_2 == 2, 2:9])*100
colMeans(prot_2[group_2 == 3, 2:9])*100
colMeans(prot_2[group_2 == 4, 2:9])*100
dist_prot_2 <- dist(prot_2[,2:10])
dist_prot_2 <- dist(prot_2[,1:10])
dist_prot_2 <- dist(prot_2[,1:9])
clust_prot_2 <- hclust(dist_prot_2, "ward.D")
clust_prot_2
plot(clust_prot_2, labels = prot[,1], hang = -1)
rect.hclust(clust_prot_2, k=4, border = "green")
group_2 <- cutree(clust_prot_2, k=4)
group_2
colMeans(prot_2[group_2 == 1, 2:9])*100
colMeans(prot_2[group_2 == 2, 2:9])*100
colMeans(prot_2[group_2 == 3, 2:9])*100
colMeans(prot_2[group_2 == 4, 2:9])*100
